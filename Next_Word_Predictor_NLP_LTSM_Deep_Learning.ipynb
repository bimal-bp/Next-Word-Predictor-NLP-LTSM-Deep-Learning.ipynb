{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1M9_qOfBezXpOtk6LygfclnjdNXw7eXvN",
      "authorship_tag": "ABX9TyMwaIIgAzKuclPzN9K0/0kw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bimal-bp/Next-Word-Predictor-NLP-LTSM-Deep-Learning.ipynb/blob/ML_MODELS/Next_Word_Predictor_NLP_LTSM_Deep_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify the path to your file in Google Drive\n",
        "file_path = '/content/drive/MyDrive/dataset (1).txt'\n",
        "\n",
        "# Open and read the file\n",
        "with open(file_path, 'r') as file:\n",
        "    lines = file.readlines()\n",
        "\n",
        "# Print specific lines from the file\n",
        "print(lines[0])\n",
        "print(lines[100])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "roZCma3pZWiA",
        "outputId": "05f28e83-cca9-4c8a-b957-9d1b247182b2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ï»¿It was the best of times, it was the worst of times, it was the age of\n",
            "\n",
            "coach across the road, with the mutinous intent of taking it back\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import libraies\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.layers import Embedding,LSTM,Dense\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import pickle\n",
        "import numpy as np\n",
        "import os"
      ],
      "metadata": {
        "id": "DDhLEORtSM_j"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lines[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OXGGpMmjYmnE",
        "outputId": "3a4120c2-a7c2-4cb9-daa9-77638f566836"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['\\ufeffIt was the best of times, it was the worst of times, it was the age of\\n',\n",
              " 'wisdom, it was the age of foolishness, it was the epoch of belief, it\\n',\n",
              " 'was the epoch of incredulity, it was the season of Light, it was the\\n',\n",
              " 'season of Darkness, it was the spring of hope, it was the winter of\\n',\n",
              " 'despair, we had everything before us, we had nothing before us, we were\\n']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# cleaning\n",
        "data=\"\"\n",
        "for i in lines:\n",
        "  data=' '.join(lines)\n",
        "data=data.replace('\\n','').replace('\\r','').replace('\\ufeff','')\n",
        "data[:200]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "UwJ8biIDYw5D",
        "outputId": "a9b36bf8-b015-440b-8b60-d7924351bb59"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'It was the best of times, it was the worst of times, it was the age of wisdom, it was the age of foolishness, it was the epoch of belief, it was the epoch of incredulity, it was the season of Light, i'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "translator=str.maketrans(string.punctuation, ' '*len(string.punctuation))\n",
        "new_data=data.translate(translator)\n",
        "\n",
        "new_data[:150]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "S2EmhV6MZ7kg",
        "outputId": "b3d9e58b-7c11-4fc2-c7f0-262164b4afce"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'It was the best of times  it was the worst of times  it was the age of wisdom  it was the age of foolishness  it was the epoch of belief  it was the e'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "z=[]\n",
        "for i in data.split():\n",
        "  if i not in z:\n",
        "    z.append(i)\n",
        "data=' '.join(z)\n",
        "data[:150]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "iJ6N9lfva-qT",
        "outputId": "ea62679e-666e-4a18-f3ed-0c215fe44826"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'It was the best of times, it worst age wisdom, foolishness, epoch belief, incredulity, season Light, Darkness, spring hope, winter despair, we had eve'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.core.displayhook import tokenize\n",
        "# tokenization\n",
        "tokenizer=Tokenizer()\n",
        "tokenizer.fit_on_texts([data])\n",
        "\n",
        "# saving the tiokenzier\n",
        "pickle.dump(tokenizer,open('tokenizer.pkl','wb'))\n",
        "\n",
        "sequence_data=tokenizer.texts_to_sequences([data])[0]\n",
        "sequence_data[0:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "52ObL6Bue6_8",
        "outputId": "1a732e0c-8afc-43f1-9c38-bb1daf1c5f0c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[4, 19, 7, 815, 59, 332, 4, 816, 507, 2956]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size=len(tokenizer.word_index)+1\n",
        "print(vocab_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SK3W5Tq7fm7u",
        "outputId": "401feade-092f-4397-9174-7ff681773787"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8697\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sequences=[]\n",
        "for i in range(1,len(sequence_data)):\n",
        "  words=sequence_data[i-1:i+1]\n",
        "  sequences.append(words)\n",
        "print(\"The length of sequences are : \",len(sequences))\n",
        "\n",
        "sequences=np.array(sequences)\n",
        "sequences[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CQCSlb7RgLk8",
        "outputId": "f2ed1d8b-7a69-4df1-9485-c1e6f367fe54"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The length of sequences are :  17085\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[   4,   19],\n",
              "       [  19,    7],\n",
              "       [   7,  815],\n",
              "       [ 815,   59],\n",
              "       [  59,  332],\n",
              "       [ 332,    4],\n",
              "       [   4,  816],\n",
              "       [ 816,  507],\n",
              "       [ 507, 2956],\n",
              "       [2956, 2957]])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x=[]\n",
        "y=[]\n",
        "for i in sequences:\n",
        "  x.append(i[0])\n",
        "  y.append(i[1])\n",
        "\n",
        "x=np.array(x)\n",
        "y=np.array(y)"
      ],
      "metadata": {
        "id": "BW256vcZg1UM"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y=to_categorical(y,num_classes=vocab_size)\n",
        "y[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hba83fXjhFyH",
        "outputId": "97829592-8aa4-4931-ec0e-6235c4771084"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model craete\n",
        "\n",
        "model=Sequential()\n",
        "model.add(Embedding(vocab_size,10,input_length=1))\n",
        "model.add(LSTM(50,return_sequences=True))\n",
        "model.add(LSTM(50))\n",
        "model.add(Dense(50,activation=\"relu\"))\n",
        "model.add(Dense(vocab_size,activation=\"softmax\"))\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YTEyqiC3hQpG",
        "outputId": "05d233f1-97cc-49d9-bb6e-f9a47c5c5d4a"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 1, 10)             86970     \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 1, 50)             12200     \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 50)                20200     \n",
            "                                                                 \n",
            " dense (Dense)               (None, 50)                2550      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 8697)              443547    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 565467 (2.16 MB)\n",
            "Trainable params: 565467 (2.16 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# callbacks\n",
        "\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "\n",
        "checkpoint=ModelCheckpoint(\"nextword1.h5\",monitor='loss',verbose=1,\n",
        "                           save_best_only=True,mode='auto')\n",
        "\n",
        "reduce=ReduceLROnPlateau(monitor='loss',factor=0.2,patience=3,min_lr=0.0001,verbose=1)\n",
        "logdir='logsnextword1'\n",
        "tensorboard_visualization=TensorBoard(log_dir=logdir)"
      ],
      "metadata": {
        "id": "NCrKBVevh9T1"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compile\n",
        "model.compile(loss='categorical_crossentropy',optimizer=Adam(lr=0.001))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QuZNjw7ikOdQ",
        "outputId": "b7afd8a7-0ebc-4563-c299-1efdc4686bc0"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x,y,epochs=5,batch_size=64,callbacks=[checkpoint, reduce, tensorboard_visualization])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PLzoDA3WklBa",
        "outputId": "7aaa6a49-3cc9-473a-bf71-bfc438ba4bf3"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "264/267 [============================>.] - ETA: 0s - loss: 8.9800\n",
            "Epoch 1: loss improved from inf to 8.98075, saving model to nextword1.h5\n",
            "267/267 [==============================] - 15s 14ms/step - loss: 8.9807 - lr: 0.0010\n",
            "Epoch 2/5\n",
            " 15/267 [>.............................] - ETA: 1s - loss: 8.6528"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "267/267 [==============================] - ETA: 0s - loss: 8.5064\n",
            "Epoch 2: loss improved from 8.98075 to 8.50642, saving model to nextword1.h5\n",
            "267/267 [==============================] - 2s 8ms/step - loss: 8.5064 - lr: 0.0010\n",
            "Epoch 3/5\n",
            "266/267 [============================>.] - ETA: 0s - loss: 8.2315\n",
            "Epoch 3: loss improved from 8.50642 to 8.23167, saving model to nextword1.h5\n",
            "267/267 [==============================] - 3s 11ms/step - loss: 8.2317 - lr: 0.0010\n",
            "Epoch 4/5\n",
            "262/267 [============================>.] - ETA: 0s - loss: 8.1008\n",
            "Epoch 4: loss improved from 8.23167 to 8.10246, saving model to nextword1.h5\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 8.1025 - lr: 0.0010\n",
            "Epoch 5/5\n",
            "264/267 [============================>.] - ETA: 0s - loss: 8.0234\n",
            "Epoch 5: loss improved from 8.10246 to 8.02669, saving model to nextword1.h5\n",
            "267/267 [==============================] - 2s 8ms/step - loss: 8.0267 - lr: 0.0010\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7d1e917a6ef0>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prediction script\n",
        "from tensorflow.keras.models import load_model\n",
        "import numpy as np\n",
        "import pickle\n",
        "\n",
        "model=load_model('nextword1.h5')\n",
        "tokenizer=pickle.load(open('tokenizer.pkl','rb'))\n",
        "\n",
        "def predict_next_word(model,tokenizer,text):\n",
        "  for i in range(3):\n",
        "    sequence=tokenizer.texts_to_sequences([text][0])\n",
        "    sequence=np.array(sequence)\n",
        "\n",
        "    preds=model.predict_classes(sequences)\n",
        "\n",
        "    for key,value in tokenizer.word_index.items():\n",
        "      if value==preds:\n",
        "        predicted_word=key\n",
        "\n",
        "    print(predicted_word)\n",
        "    return predicted_word"
      ],
      "metadata": {
        "id": "CTW0VURN5CBs"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "while(True):\n",
        "\n",
        "  text=input(\"enter ur line : \")\n",
        "\n",
        "  if text == \"stop the script\":\n",
        "    print(\"end the progam\")\n",
        "    break\n",
        "  else:\n",
        "    try:\n",
        "      text=text.split(\" \")\n",
        "      text=text[-1]\n",
        "\n",
        "      text=' '.join(text)\n",
        "      predict_next_word(model,tokenizer,text)\n",
        "    except:\n",
        "\n",
        "      continue"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5G4iA8gt6V-5",
        "outputId": "c93cdaef-8c47-4e1b-d28c-2f3f4c29ce99"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "enter ur line : stop the script\n",
            "end the progam\n"
          ]
        }
      ]
    }
  ]
}